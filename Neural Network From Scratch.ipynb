{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a88b972",
   "metadata": {},
   "source": [
    "# Neural Network Built from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ed3bbd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7fe9ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"insurance.csv\")\n",
    "(x_train,x_test,y_train,y_test)=tts(df[['age','affordibility']], df.bought_insurance, test_size=0.2)\n",
    "x_train_scaled=x_train.copy()\n",
    "x_train_scaled['age']=x_train_scaled['age']/max(x_train_scaled['age'])\n",
    "x_test_scaled=x_test.copy()\n",
    "x_test_scaled['age']=x_test_scaled['age']/max(x_test_scaled['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "aad62e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN:\n",
    "    def __init__(self):\n",
    "        self.w1=1\n",
    "        self.w2=1\n",
    "        self.bias=0\n",
    "        self.loss=0\n",
    "    def logloss(self,y_true,y_pred):\n",
    "        epsilon=1e-15\n",
    "        y_pred_new=[max(i,epsilon) for i in y_pred]\n",
    "        y_pred_new1=[min(i,(1-epsilon)) for i in y_pred_new]\n",
    "        y_pred_new2=np.array(y_pred_new1)\n",
    "        return -np.mean(y_true*np.log(y_pred_new2)+(1-y_true)*np.log(1-y_pred_new2))\n",
    "    def sigmoid_numpy(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    def gradient_descent(self,age, affordibility, y_true, epochs, loss_threshold):\n",
    "        w1=1\n",
    "        w2=1\n",
    "        rate=0.5\n",
    "        bias=0\n",
    "        n=len(age)\n",
    "        for i in range(epochs):\n",
    "            ws=w1*age+w2*affordibility+bias\n",
    "            y_pred=self.sigmoid_numpy(ws)\n",
    "        \n",
    "            loss=self.logloss(y_true, y_pred)\n",
    "\n",
    "            w1d=(1/n)*np.dot(np.transpose(age), (y_pred-y_true))\n",
    "            w2d=(1/n)*np.dot(np.transpose(affordibility),(y_pred-y_true))\n",
    "            bias_d=np.mean(y_pred-y_true)\n",
    "            \n",
    "            w1=w1-rate*w1d\n",
    "            w2=w2-rate*w2d\n",
    "            bias=bias-rate*bias_d\n",
    "            if loss<=loss_threshold:\n",
    "                break\n",
    "            if i%50==0:\n",
    "                print(f'W1: {w1} W2:{w2} Bias : {bias} Loss : {loss}')\n",
    "        return w1,w2,bias,loss\n",
    "        \n",
    "    def fit(self,x_train,y_train, epochs,lt):\n",
    "        self.w1,self.w2,self.bias,self.loss=self.gradient_descent(x_train['age'], x_train['affordibility'], y_train, epochs, lt)\n",
    "    def predict(self,x_test):\n",
    "        return self.sigmoid_numpy(self.w1*x_test['age']+self.w2*x_test['affordibility']+self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "169c22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 0.9487133076884546 W2:0.9412334028325896 Bias : -0.13652075867887578 Loss : 0.7256439008018725\n",
      "W1: 1.5362996748218887 W2:1.2570290068119763 Bias : -1.6853916757024143 Loss : 0.4948209166986942\n",
      "W1: 2.312391434694692 W2:1.5550962110629467 Bias : -2.425918880389027 Loss : 0.4444537019545774\n",
      "W1: 2.969124309124307 W2:1.7233789809172702 Bias : -2.9845613318333073 Loss : 0.41325904589964163\n",
      "W1: 3.5203910261081415 W2:1.839680680486152 Bias : -3.4318928305305967 Loss : 0.39237861126191986\n",
      "W1: 3.9844398702532344 W2:1.9323525290551726 Bias : -3.80312037463856 Loss : 0.37779914949261517\n",
      "W1: 4.377908171694351 W2:2.0124114491797713 Bias : -4.118364125535876 Loss : 0.36730385668907994\n",
      "W1: 4.714453408561327 W2:2.0843651176496674 Bias : -4.3903496992451645 Loss : 0.3595595005252927\n",
      "W1: 5.00486664100491 W2:2.1501779236935814 Bias : -4.627755056248463 Loss : 0.3537252001978748\n",
      "W1: 5.25757217875125 W2:2.2108016883212604 Bias : -4.8368355075580585 Loss : 0.3492517743615328\n",
      "W1: 5.479146613647904 W2:2.2667834774003057 Bias : -5.022288812595987 Loss : 0.34576987810752735\n",
      "W1: 5.674754194644219 W2:2.3185088767872313 Bias : -5.187753292986133 Loss : 0.3430246248610342\n",
      "W1: 5.848485532053313 W2:2.3662978827221814 Bias : -5.336114200752295 Loss : 0.3408360366433125\n",
      "W1: 6.003613228181536 W2:2.410440863327685 Bias : -5.469702714450265 Loss : 0.33907440795348853\n",
      "W1: 6.142782718643504 W2:2.4512105627820504 Bias : -5.590431076791094 Loss : 0.3376445490746901\n",
      "W1: 6.26815455547999 W2:2.488865039046311 Bias : -5.6998877444418605 Loss : 0.336475461662775\n",
      "W1: 6.381510882393232 W2:2.5236476193239663 Bias : -5.799406384071048 Loss : 0.33551342175969273\n",
      "W1: 6.484335630553467 W2:2.5557862488010525 Bias : -5.89011712748251 Loss : 0.3347172502419024\n",
      "W1: 6.577875403524599 W2:2.585493059058389 Bias : -5.972985419857256 Loss : 0.33405501804307797\n",
      "W1: 6.663186106233371 W2:2.612964356960244 Bias : -6.048841966556691 Loss : 0.333501711394417\n",
      "W1: 6.741168980783615 W2:2.638381002831499 Bias : -6.118406154101793 Loss : 0.3330375513462551\n",
      "W1: 6.812598710813301 W2:2.6619090785594084 Bias : -6.1823045981732445 Loss : 0.3326467668368188\n",
      "W1: 6.878145538616402 W2:2.6837007422470025 Bias : -6.241085994873829 Loss : 0.33231668712073464\n",
      "W1: 6.93839282443987 W2:2.703895183654843 Bias : -6.295233128787693 Loss : 0.33203706234236696\n",
      "W1: 6.993851106544512 W2:2.722619616485358 Bias : -6.345172667762724 Loss : 0.3317995492792996\n",
      "W1: 7.044969452053108 W2:2.73999026314202 Bias : -6.391283216238849 Loss : 0.3315973181465762\n",
      "W1: 7.0921446928498355 W2:2.7561133031308676 Bias : -6.433901985157509 Loss : 0.3314247491492803\n",
      "W1: 7.135728997105831 W2:2.7710857677985183 Bias : -6.473330353303967 Loss : 0.3312771962765893\n",
      "W1: 7.176036120764398 W2:2.7849963722703373 Bias : -6.509838533274701 Loss : 0.3311508019709479\n",
      "W1: 7.213346604179925 W2:2.797926281025499 Bias : -6.543669508989027 Loss : 0.33104235064181337\n",
      "W1: 7.24791211971172 W2:2.809949807203185 Bias : -6.575042376550951 Loss : 0.3309491520908765\n",
      "W1: 7.279959131167726 W2:2.8211350480232587 Bias : -6.604155193354163 Loss : 0.3308689481527555\n",
      "W1: 7.309691991790726 W2:2.8315444600416897 Bias : -6.631187419506924 Loss : 0.3307998374875215\n",
      "W1: 7.337295581241389 W2:2.8412353786512137 Bias : -6.656302019418581 Loss : 0.3307402146640159\n",
      "W1: 7.3629375617621635 W2:2.8502604864996037 Bias : -6.679647278629992 Loss : 0.33068872056696097\n",
      "W1: 7.386770317938548 W2:2.8586682354855553 Bias : -6.701358380871429 Loss : 0.3306442018311938\n",
      "W1: 7.4089326321278 W2:2.8665032268113464 Bias : -6.721558782285434 Loss : 0.33060567751299075\n",
      "W1: 7.429551137895003 W2:2.8738065532944908 Bias : -6.740361413302387 Loss : 0.33057231159428485\n",
      "W1: 7.448741586080424 W2:2.8806161078154564 Bias : -6.7578697334562765 Loss : 0.33054339021151\n",
      "W1: 7.466609951966565 W2:2.8869668614366617 Bias : -6.774178660212551 Loss : 0.3305183027293355\n",
      "W1: 7.483253407074166 W2:2.8928911143889966 Bias : -6.78937538944499 Loss : 0.3304965259571592\n",
      "W1: 7.498761175131387 W2:2.898418722798178 Bias : -6.8035401223860195 Loss : 0.33047761094509265\n",
      "W1: 7.513215288527698 W2:2.903577303720792 Bias : -6.816746711561267 Loss : 0.3304611719053777\n",
      "W1: 7.5266912589283415 W2:2.908392420782261 Bias : -6.829063236307551 Loss : 0.3304468768915292\n",
      "W1: 7.539258673565774 W2:2.9128877524570553 Bias : -6.8405525168875405 Loss : 0.33043443993612553\n",
      "W1: 7.550981726946505 W2:2.917085244804764 Bias : -6.851272574892919 Loss : 0.3304236144029968\n",
      "W1: 7.561919696241601 W2:2.921005250273004 Bias : -6.861277046522918 Loss : 0.33041418735354805\n",
      "W1: 7.5721273674079015 W2:2.924666653997715 Bias : -6.87061555439757 Loss : 0.33040597476242456\n",
      "W1: 7.581655418068402 W2:2.9280869888712857 Bias : -6.879334042783632 Loss : 0.3303988174464289\n",
      "W1: 7.590550762327437 W2:2.9312825405072687 Bias : -6.8874750804507014 Loss : 0.3303925775939415\n",
      "W1: 7.598856861979054 W2:2.9342684431051183 Bias : -6.8950781348148436 Loss : 0.33038713580113027\n",
      "W1: 7.606614007962084 W2:2.9370587671077883 Bias : -6.902179820550509 Loss : 0.33038238853682994\n",
      "W1: 7.613859575403004 W2:2.939666599447326 Bias : -6.908814125444784 Loss : 0.33037824597078963\n",
      "W1: 7.620628255152336 W2:2.9421041170874127 Bias : -6.915012615919833 Loss : 0.3303746301105491\n",
      "W1: 7.62695226434918 W2:2.9443826544956853 Bias : -6.920804624350573 Loss : 0.33037147320094895\n",
      "W1: 7.632861538231037 W2:2.946512765611431 Bias : -6.926217420047219 Loss : 0.33036871634752957\n",
      "W1: 7.638383905133776 W2:2.9485042808148783 Bias : -6.931276365550393 Loss : 0.33036630833111214\n",
      "W1: 7.643545246392193 W2:2.950366359351674 Bias : -6.936005059694076 Loss : 0.3303642045858868\n",
      "W1: 7.648369642649506 W2:2.9521075376196766 Bias : -6.940425468725056 Loss : 0.3303623663175481\n",
      "W1: 7.652879507908988 W2:2.953735773683873 Bias : -6.9445580466223005 Loss : 0.330360759741552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2     0.859530\n",
       "7     0.613409\n",
       "11    0.369325\n",
       "1     0.020616\n",
       "27    0.843947\n",
       "8     0.975008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn=MyNN()\n",
    "nn.fit(x_train_scaled,y_train, 3000, 0.3059)\n",
    "nn.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "65d67486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "7     1\n",
       "11    0\n",
       "1     0\n",
       "27    0\n",
       "8     1\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
