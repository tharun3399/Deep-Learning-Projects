{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb878e9b",
   "metadata": {},
   "source": [
    "# Neural Network Built from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9290001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3874b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"insurance.csv\")\n",
    "(x_train,x_test,y_train,y_test)=tts(df[['age','affordibility']], df.bought_insurance, test_size=0.2)\n",
    "x_train_scaled=x_train.copy()\n",
    "x_train_scaled['age']=x_train_scaled['age']/max(x_train_scaled['age'])\n",
    "x_test_scaled=x_test.copy()\n",
    "x_test_scaled['age']=x_test_scaled['age']/max(x_test_scaled['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e659f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN:\n",
    "    def __init__(self):\n",
    "        self.w1=1\n",
    "        self.w2=1\n",
    "        self.bias=0\n",
    "        self.loss=0\n",
    "    def logloss(self,y_true,y_pred):\n",
    "        epsilon=1e-15\n",
    "        y_pred_new=[max(i,epsilon) for i in y_pred]\n",
    "        y_pred_new1=[min(i,(1-epsilon)) for i in y_pred_new]\n",
    "        y_pred_new2=np.array(y_pred_new1)\n",
    "        return -np.mean(y_true*np.log(y_pred_new2)+(1-y_true)*np.log(1-y_pred_new2))\n",
    "    def sigmoid_numpy(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    def gradient_descent(self,age, affordibility, y_true, epochs, loss_threshold):\n",
    "        w1=1\n",
    "        w2=1\n",
    "        rate=0.5\n",
    "        bias=0\n",
    "        n=len(age)\n",
    "        for i in range(epochs):\n",
    "            ws=w1*age+w2*affordibility+bias\n",
    "            y_pred=self.sigmoid_numpy(ws)\n",
    "        \n",
    "            loss=self.logloss(y_true, y_pred)\n",
    "\n",
    "            w1d=(1/n)*np.dot(np.transpose(age), (y_pred-y_true))\n",
    "            w2d=(1/n)*np.dot(np.transpose(affordibility),(y_pred-y_true))\n",
    "            bias_d=np.mean(y_pred-y_true)\n",
    "            \n",
    "            w1=w1-rate*w1d\n",
    "            w2=w2-rate*w2d\n",
    "            bias=bias-rate*bias_d\n",
    "            if loss<=loss_threshold:\n",
    "                break\n",
    "            if i%50==0:\n",
    "                print(f'W1: {w1} W2:{w2} Bias : {bias} Loss : {loss}')\n",
    "        return w1,w2,bias,loss\n",
    "        \n",
    "    def fit(self,x_train,y_train, epochs,lt):\n",
    "        self.w1,self.w2,self.bias,self.loss=self.gradient_descent(x_train['age'], x_train['affordibility'], y_train, epochs, lt)\n",
    "    def predict(self,x_test):\n",
    "        return self.sigmoid_numpy(self.w1*x_test['age']+self.w2*x_test['affordibility']+self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e4299a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 0.92623275744421 W2:0.912587943211167 Bias : -0.17221790880052765 Loss : 0.8507083052946693\n",
      "W1: 1.4745763894900308 W2:0.8208981601769906 Bias : -1.6578524636302314 Loss : 0.5440525150815163\n",
      "W1: 2.2635971228690615 W2:0.9642570791718893 Bias : -2.2710902483102275 Loss : 0.5027745946845089\n",
      "W1: 2.9077360921435575 W2:1.0464116512650887 Bias : -2.749512481265359 Loss : 0.47648635934081907\n",
      "W1: 3.4350590662132037 W2:1.107444953438419 Bias : -3.138713628204941 Loss : 0.4589987349718568\n",
      "W1: 3.870973455373435 W2:1.1593999435845812 Bias : -3.4630745872074677 Loss : 0.4469843702783288\n",
      "W1: 4.235431293710049 W2:1.205977787934397 Bias : -3.737710234352775 Loss : 0.43850494706225435\n",
      "W1: 4.5434862503802735 W2:1.2483842624078947 Bias : -3.9729365970788293 Loss : 0.43238235257927843\n",
      "W1: 4.806433390188716 W2:1.2871001231316663 Bias : -4.17622673488312 Loss : 0.42787533056181615\n",
      "W1: 5.032813457114598 W2:1.322413753540704 Bias : -4.353206044203149 Loss : 0.42450282234528436\n",
      "W1: 5.229167346847832 W2:1.3545726054860505 Bias : -4.5082239184235195 Loss : 0.4219438496989945\n",
      "W1: 5.400576113534098 W2:1.3838187231804784 Bias : -4.644711848723079 Loss : 0.41997890371959995\n",
      "W1: 5.551043023648608 W2:1.4103914305208252 Bias : -4.765421498807389 Loss : 0.41845456504100115\n",
      "W1: 5.6837647707073025 W2:1.4345227696986567 Bias : -4.872589671740458 Loss : 0.4172615278624914\n",
      "W1: 5.8013259057804945 W2:1.456432979350519 Bias : -4.968056125448264 Loss : 0.416320585867226\n",
      "W1: 5.9058399737033485 W2:1.4763275878783724 Bias : -5.053349703881625 Loss : 0.4155734785048445\n",
      "W1: 5.999053341751037 W2:1.4943960539569017 Bias : -5.129752516118926 Loss : 0.41497678035061\n",
      "W1: 6.0824226106640005 W2:1.5108115300474674 Bias : -5.198348538094895 Loss : 0.4144977405852143\n",
      "W1: 6.1571730818600425 W2:1.525731343535217 Bias : -5.260060941752246 Loss : 0.4141113991062966\n",
      "W1: 6.224343464778342 W2:1.5392978914268132 Bias : -5.315681129687806 Loss : 0.4137985548314677\n",
      "W1: 6.284820463047507 W2:1.5516397420682866 Bias : -5.3658915769592666 Loss : 0.4135443131049781\n",
      "W1: 6.339365825127725 W2:1.562872811645189 Bias : -5.411283988633608 Loss : 0.4133370331141849\n",
      "W1: 6.388637719341492 W2:1.5731015349042416 Bias : -5.452373872175051 Loss : 0.4131675557791031\n",
      "W1: 6.433207787118881 W2:1.5824199837971793 Bias : -5.489612336154226 Loss : 0.4130286310242423\n",
      "W1: 6.473574871174141 W2:1.590912909753332 Bias : -5.523395721671591 Loss : 0.4129144885917617\n",
      "W1: 6.510176160415398 W2:1.5986566990416011 Bias : -5.554073524658896 Loss : 0.4128205134056382\n",
      "W1: 6.543396309380052 W2:1.6057202390224086 Bias : -5.581954958767929 Loss : 0.4127429979103413\n",
      "W1: 6.573574955732733 W2:1.6121656979409091 Bias : -5.607314428306078 Loss : 0.4126789516463025\n",
      "W1: 6.601012960402248 W2:1.618049223549988 Bias : -5.6303961206790865 Loss : 0.41262595377774836\n",
      "W1: 6.625977621277467 W2:1.6234215671084855 Bias : -5.651417882507687 Loss : 0.4125820381280929\n",
      "W1: 6.648707056050657 W2:1.6283286397154781 Bias : -5.670574509083503 Loss : 0.4125456030120029\n",
      "W1: 6.66941390786546 W2:1.6328120078602446 Bias : -5.6880405503266624 Loss : 0.4125153401204749\n",
      "W1: 6.688288495384408 W2:1.636909334708852 Bias : -5.703972715887121 Loss : 0.41249017814474376\n",
      "W1: 6.705501504211494 W2:1.6406547731489978 Bias : -5.718511946024537 Loss : 0.41246923787322926\n",
      "W1: 6.7212062974532065 W2:1.6440793160592249 Bias : -5.731785202326805 Loss : 0.4124517962712917\n",
      "W1: 6.735540908232691 W2:1.6472111087072336 Bias : -5.7439070223833895 Loss : 0.4124372576319884\n",
      "W1: 6.748629765192573 W2:1.6500757276436204 Bias : -5.7549808746160425 Loss : 0.41242513032073874\n",
      "W1: 6.760585192692799 W2:1.6526964299571474 Bias : -5.7651003431342005 Loss : 0.4124150079658632\n",
      "W1: 6.771508719975345 W2:1.6550943763024677 Bias : -5.774350167381397 Loss : 0.4124065541977512\n",
      "W1: 6.781492227608099 W2:1.6572888307028257 Bias : -5.7828071572098425 Loss : 0.41239949023176015\n",
      "W1: 6.790618954716003 W2:1.6592973397672053 Bias : -5.790541000659938 Loss : 0.4123935847383674\n",
      "W1: 6.798964386613935 W2:1.6611358936410128 Bias : -5.797614978973718 Loss : 0.4123886455592766\n",
      "W1: 6.806597039283688 W2:1.6628190707278685 Bias : -5.80408660111316 Loss : 0.41238451291802497\n",
      "W1: 6.813579154540559 W2:1.6643601679734286 Bias : -5.810008168190404 Loss : 0.4123810538440924\n",
      "W1: 6.819967317598604 W2:1.6657713182866596 Bias : -5.815427276671593 Loss : 0.41237815758501273\n",
      "W1: 6.825813006978429 W2:1.6670635964857392 Bias : -5.820387267929283 Loss : 0.4123757318249\n",
      "W1: 6.831163085235804 W2:1.66824711499152 Bias : -5.824927630642473 Loss : 0.41237369956269726\n",
      "W1: 6.836060237768105 W2:1.6693311103481399 Bias : -5.829084361640394 Loss : 0.41237199653129475\n",
      "W1: 6.840543365932952 W2:1.6703240215251707 Bias : -5.832890290025055 Loss : 0.41237056906094555\n",
      "W1: 6.84464793985437 W2:1.6712335608463893 Bias : -5.836375368764126 Loss : 0.4123693723083184\n",
      "W1: 6.8484063155667405 W2:1.6720667782945153 Bias : -5.83956693739917 Loss : 0.4123683687869532\n",
      "W1: 6.851848020533089 W2:1.6728301198575495 Bias : -5.842489959048964 Loss : 0.41236752714655844\n",
      "W1: 6.855000011052514 W2:1.6735294805088365 Bias : -5.845167234489753 Loss : 0.4123668211580448\n",
      "W1: 6.857886904626578 W2:1.674170252348499 Bias : -5.847619595753003 Loss : 0.41236622886888397\n",
      "W1: 6.860531189973711 W2:1.6747573683770627 Bias : -5.849866081387711 Loss : 0.41236573189964215\n",
      "W1: 6.8629534170535695 W2:1.675295342322182 Bias : -5.8519240952808325 Loss : 0.4123653148576612\n",
      "W1: 6.865172369181661 W2:1.6757883048951492 Bias : -5.853809550710023 Loss : 0.41236496484804824\n",
      "W1: 6.867205219070973 W2:1.6762400368149066 Bias : -5.855537001112318 Loss : 0.4123646710655686\n",
      "W1: 6.869067670426385 W2:1.6766539989027172 Bias : -5.857119758886489 Loss : 0.4123644244538667\n",
      "W1: 6.870774086534036 W2:1.677033359519964 Bias : -5.858570003401866 Loss : 0.4123642174207531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9     0.936423\n",
       "17    0.913079\n",
       "2     0.752606\n",
       "20    0.139840\n",
       "24    0.810082\n",
       "14    0.792141\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn=MyNN()\n",
    "nn.fit(x_train_scaled,y_train, 3000, 0.3059)\n",
    "nn.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a26e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     1\n",
       "17    1\n",
       "2     1\n",
       "20    0\n",
       "24    1\n",
       "14    1\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
